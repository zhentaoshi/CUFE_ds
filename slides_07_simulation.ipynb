{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2bf38c5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Simulation and Bootstrap\n",
    "\n",
    "Zhentao Shi\n",
    "\n",
    "<!-- code is tested on SCRP -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b76d41",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(magrittr)\n",
    "library(tibble)\n",
    "library(plyr)\n",
    "set.seed(888)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10364ad8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simulation\n",
    "\n",
    "\n",
    "* check finite-sample performance\n",
    "* bootstrap, a data-driven inference procedure\n",
    "* generate non-standard distributions\n",
    "* approximate integrals with no analytic expressions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2d8eda",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Appetizer\n",
    "\n",
    "calculating $\\pi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394aa51f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "require(plotrix)\n",
    "require(grid)\n",
    "\n",
    "plot(c(-1, 1), c(-1, 1), type = \"n\", asp = 1, xlab = \"x\", ylab = \"y\")\n",
    "rect(-1, -1, 1, 1)\n",
    "draw.circle(0, 0, 1)\n",
    "points(x = runif(100) * 2 - 1, y = runif(100) * 2 - 1, pch = 20, col = \"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa15f7dd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "By laws of large numbers, $\\pi$ can be approximated by a stochastic algorithm\n",
    "\n",
    "$$\n",
    "E\\left[\\boldsymbol{1}\\left\\{ x^{2}+y^{2}\\leq1\\right\\} \\right] = \\frac{\\pi r^{2}}{\\left(2r\\right)^{2}}= \\frac{\\pi}{4}\n",
    "$$\n",
    "\n",
    "it implies  $\\pi=4\\times E[ 1 \\{  x^{2}+y^{2}\\leq1 \\}]$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070e3943",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "n <- 20000000\n",
    "Z <- 2 * matrix(runif(n), ncol = 2) - 1 # uniform distribution in [-1, 1]\n",
    "\n",
    "inside <- mean(sqrt(rowSums(Z^2)) <= 1) # the center of the circle is (0, 0)\n",
    "cat(\"The estimated pi = \", inside * 4, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3965ef85",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Sample size can be made as large as the computer's memory permits.\n",
    "* Iterate it with average of averages and so on, for higher accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b5c418",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Writing Script\n",
    "\n",
    "* A script is a piece of code for a particular purpose. Thousands of lines are not written from the beginning to the end. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4be764",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Recursively development\n",
    "  * small manageable tasks\n",
    "  * test code constantly \n",
    "  * encapsulate into DIY functions\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e79d2e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Integrate small pieces into the super structure. \n",
    "* Add comments to the script to facilitate readability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd95ee8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Finite Sample Evaluation\n",
    "\n",
    "* Real world sample is finite\n",
    "* Asymptotic theory is a mathematical apparatus to approximate finite sample distributions\n",
    "* Modern econometric theory is built on asymptotics\n",
    "* Simulation is one way to evaluate the accuracy of approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9df34b2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example\n",
    "\n",
    "For the OLS estimator, \n",
    "\n",
    "* Classical views $X$ as fixed regressions and only cares about the randomness of the error term.\n",
    "* Modern econometrics textbook emphasizes that a random $X$ is more appropriate\n",
    "for econometrics applications. \n",
    "* In rigorous textbooks, the moment of $X$ is explicitly stated as $E[X_i X_i'] < \\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ebeec0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* A Pareto distribution with shape coefficient between 1 and 2 has finite population mean, but infinite variance. \n",
    "* If $X$ follows a\n",
    "[Pareto distribution](https://en.wikipedia.org/wiki/Pareto_distribution) with shape coefficient 1.5, it violates the assumptions for OLS stated in most of econometric textbooks.\n",
    "* Question: Is asymptotic inferential theory for the OLS estimator valid? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0586c3d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We write a script to investigate this problem. The following steps develop the code.\n",
    "\n",
    " 1. given a sample size, get the OLS `b_hat` and its associated `t_value`.\n",
    " 2. wrap `t_value` as a user-defined function so that we can reuse it for many times.\n",
    " 3. given a sample size, report the size under two distributions.\n",
    " 4. wrap step 3 again as a user-defined function, ready for different sample sizes.\n",
    " 5. develop the super structure to connect the workhorse functions.\n",
    " 6. add comments and documentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050bb089",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $t$-statistic\n",
    "\n",
    "$$\n",
    "\\sqrt{n} (\\hat{\\beta} - \\beta_0) |X = (X'X/n)^{-1}  (X' e /\\sqrt{n}),\n",
    "$$\n",
    "\n",
    "the $k$-th element of the vector coefficient conditional on $X$ is\n",
    "$$\n",
    "\\widehat{\\beta}_{k}|X=\\eta_{k}'\\widehat{\\beta}|X\n",
    "\\sim N\\left(\\beta_{k},\\sigma^{2}\\left(X'X\\right)_{kk}^{-1}\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c970f7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# the workhorse functions\n",
    "simulation <- function(n, type = \"Normal\", df = df) {\n",
    "  # a function gives the t-value under the null\n",
    "  if (type == \"Normal\") {\n",
    "    e <- rnorm(n)\n",
    "  } else if (type == \"T\") {\n",
    "    e <- rt(n, df)\n",
    "  }\n",
    "\n",
    "  X <- cbind(1, VGAM::rpareto(n, shape = 1.5))\n",
    "  Y <- X %*% b0 + e\n",
    "  rm(e)\n",
    "\n",
    "  bhat <- solve(t(X) %*% X, t(X) %*% Y)\n",
    "  bhat2 <- bhat[2] # parameter we want to test\n",
    "\n",
    "  e_hat <- Y - X %*% bhat\n",
    "  sigma_hat_square <- sum(e_hat^2) / (n - 2)\n",
    "  sig_B <- solve(t(X) %*% X) * sigma_hat_square\n",
    "  t_value_2 <- (bhat2 - b0[2]) / sqrt(sig_B[2, 2])\n",
    "\n",
    "  return(t_value_2)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21799fd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# report the empirical test size\n",
    "report <- function(n) {\n",
    "  # collect the test size from the two distributions\n",
    "  # this function contains some repetitive code, but is OK for such a simple one\n",
    "  TEST_SIZE <- rep(0, 3)\n",
    "\n",
    "  # e ~ normal distribution, under which the t-dist is exact\n",
    "  Res <- plyr::ldply(.data = 1:Rep, .fun = function(i) simulation(n, \"Normal\"))\n",
    "  TEST_SIZE[1] <- mean(abs(Res) > qt(.975, n - 2))\n",
    "  TEST_SIZE[2] <- mean(abs(Res) > qnorm(.975))\n",
    "\n",
    "  # e ~ t-distribution, under which the exact distribution is complicated.\n",
    "  # we rely on asymptotic normal distribution for inference instead\n",
    "  Res <- plyr::ldply(.data = 1:Rep, .fun = function(i) simulation(n, \"T\", df))\n",
    "  TEST_SIZE[3] <- mean(abs(Res) > qnorm(.975))\n",
    "\n",
    "  return(TEST_SIZE)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf56761",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## the super structure\n",
    "# set the parameters\n",
    "Rep <- 1000\n",
    "b0 <- matrix(1, nrow = 2)\n",
    "df <- 1 # t dist. with df = 1 is Cauchy\n",
    "\n",
    "# run the calculation of the empirical sizes for different sample sizes\n",
    "NN <- c(5, 10, 200, 5000)\n",
    "RES <- plyr::ldply(.data = NN, .fun = report)\n",
    "names(RES) <- c(\"exact\", \"normal.asym\", \"cauchy.asym\") # to make the results readable\n",
    "RES$n <- NN\n",
    "RES <- RES[, c(4, 1:3)] # beautify the print\n",
    "print(RES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456a0cb9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Simulation Results\n",
    "\n",
    "* 1st column: the error is normal, use exact distribution theory to find the critical value (according to $t$-distribution.)\n",
    "\n",
    "* 2nd column: still uses the normal error\n",
    "  * change the critical value to asymptotic normal distribution\n",
    "  \n",
    "* 3rd column: error distribution is Cauchy\n",
    "  * asymptotic approximation breaks down\n",
    "  * test size does not converge to the nominal 5%  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2165ba",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Observations\n",
    "\n",
    "* $X$ is always Pareto \n",
    "* distribution of $X$ doesn't matter in our simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a89e2b",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Justification\n",
    "\n",
    "\n",
    "The $t$-statistic\n",
    "\n",
    "$$\n",
    "T_{k}  =\\frac{\\widehat{\\beta}_{k}-\\beta_{k}}{\\sqrt{s^{2}\\left[\\left(X'X\\right)^{-1}\\right]_{kk}}} =\\frac{\\widehat{\\beta}_{k}-\\beta_{k}}{\\sqrt{\\sigma^{2}\\left[\\left(X'X\\right)^{-1}\\right]_{kk}}}\\cdot\\frac{\\sqrt{\\sigma^{2}}}{\\sqrt{s^{2}}}\\\\\n",
    "  =\\frac{\\left(\\widehat{\\beta}_{k}-\\beta_{k}\\right)/\\sqrt{\\sigma^{2}\\left[\\left(X'X\\right)^{-1}\\right]_{kk}}}{\\sqrt{\\frac{e'}{\\sigma}M_{X}\\frac{e}{\\sigma}/\\left(n-K\\right)}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c1b815",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "* Self-normalized $t$ statistic does not break down despite that $X'X/n$ does not converge\n",
    "* Regardless the distribution of $X$, when the error term is normal \n",
    "  * numerator follows $N(0,1)$\n",
    "  * demonimator follows $\\chi^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b63ffb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### World View\n",
    "\n",
    "\n",
    "* Fundamental question: how to quantify uncertainty.\n",
    "  * data $(X_1,X_2,\\ldots,X_n)$\n",
    "  * sample mean $\\bar{X}$\n",
    "  * sample variance $s$\n",
    "  * frequentist confidence interval about the population mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98f4c4c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Asymptotics is imaginary.\n",
    "* Let's be realistic: we have a finite sample $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f0e0cd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bootstrap\n",
    "\n",
    "* Let $X_1, X_2, \\ldots, X_n \\sim F$ be an i.i.d. sample of $n$ observations following a distribution $F$. \n",
    "* The finite sample distribution of a statistic $T_n(\\theta)\\sim G_n(\\cdot, F)$ usually depends on the sample size $n$, as well as the unknown true distribution $F$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228c99b9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Key Idea\n",
    "\n",
    "* Bootstrap replaces the unknown distribution $F$ in $G_n(\\cdot, F)$ by the empirical distribution function\n",
    "\n",
    "$$\n",
    "\\hat{F}_n(\\cdot) = n^{-1} \\sum_{i=1}^n 1\\{\\cdot \\leq X_i\\}\n",
    "$$\n",
    "\n",
    "* Bootstrap inference is drawn from the bootstrap distribution\n",
    "\n",
    "$$\n",
    "G_n(\\cdot, \\hat{F}_n)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a21b6b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Compare to Asymptotic Theory\n",
    "\n",
    "* Bootstrap is a finite-sample practice \n",
    "* It doesn't refer to an imaginary world where $n\\to \\infty$ at its face value\n",
    "\n",
    "\n",
    "* Asymptotic theory approximates $G_n(\\cdot, F)$ by its limit \n",
    "\n",
    "$$G(\\cdot, F) := \\lim_{n\\to\\infty} G_n(\\cdot, F).$$ \n",
    "\n",
    "* In many cases $G(\\cdot, F)$ is independent of $F$ and it becomes $G(\\cdot)$. Such a $T_n(\\theta)$ is called *asymptotically pivotal*, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920e2493",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "runif(10) %>%\n",
    "  ecdf() %>%\n",
    "  plot(, xlim = c(0, 1), main = \"ECDF for uniform distribution\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53f96ea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Nonparametric Bootstrap\n",
    "\n",
    "* Implementation of bootstrap is a simulation exercise. \n",
    "* In an i.i.d. environment, $n$ observations are drawn with equal weight and **with replacement** from the realized sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe7d5d1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Variants of Bootstrap Schemes\n",
    "\n",
    "* Block bootstrap: preserve dependence structure\n",
    "  * dependent dataset such as time series\n",
    "  * clustering data or networks\n",
    "\n",
    "* parametric bootstrap\n",
    "  * In regressions we fix the regressors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bc6ceb",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "* wild bootstrap: [[Davidson, 2010]](https://www.tandfonline.com/doi/abs/10.1198/jbes.2009.07221?journalCode=ubes20)\n",
    "  * Heteroskedascity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a07e813",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "n <- 9 # real sample size\n",
    "real_sample <- rnorm(n) # the real sample\n",
    "d0 <- tibble(no = 1:n, x = real_sample)\n",
    "print(d0)\n",
    "\n",
    "###### bootstrap \n",
    "boot_Rep <- 3 # bootstrap 3 times\n",
    "d_boot <- list() # save the bootstrap sample\n",
    "for (b in 1:boot_Rep) {\n",
    "  boot_index <- sample(1:n, n, replace = TRUE)\n",
    "  d_boot[[b]] <- tibble(no = boot_index, x = real_sample[boot_index])\n",
    "}\n",
    "\n",
    "d_boot %>% as_tibble(, .name_repair = \"minimal\") %>% print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ec6dff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bootstrap Estimation\n",
    "\n",
    "\n",
    "* R package [boot](http://cran.r-project.org/web/packages/boot/index.html) provides a general function `boot()`.\n",
    "* `ply`-family functions for repeated simulations. \n",
    "\n",
    "* Bootstrap is convenient. \n",
    "  * Analytic formula of the variance of an econometric estimator can be complex to derive or code up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d036c9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example\n",
    "\n",
    "* One of the most popular estimators for a sample selection model is @heckman1977sample's two-step method\n",
    "\n",
    "* Outcome equation\n",
    "\n",
    "$$\n",
    "y_i = x_i \\beta + u_i\n",
    "$$\n",
    "\n",
    "and the selection equation be\n",
    "\n",
    "$$\n",
    "D_i = z_i \\gamma + v_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07915894",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* To obtain a point estimator, we simply run a Probit in the selection model, predict the probability of participation, and then run an OLS of $y_i$ on $x_i$ and $\\lambda (\\hat{D}_i)$ in the outcome model, where $\\lambda(\\cdot)$ is the inverse Mill's ratio. \n",
    "\n",
    "* From Heckman (1979)'s original paper, the asymptotic variance expression of the two-step estimator is very complicated.\n",
    "\n",
    "* Instead of following the analytic formula, we can simply bootstrap the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a21b68d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# the dataset comes from\n",
    "# Greene( 2003 ): example 22.8, page 786\n",
    "library(sampleSelection)\n",
    "data(Mroz87)\n",
    "# equations\n",
    "selection_eq <- lfp ~ -1 + age + faminc + exper + educ\n",
    "outcome_eq <- wage ~ exper + educ\n",
    "\n",
    "# Heckman two-step estimation\n",
    "heck <- sampleSelection::heckit(selection_eq, outcome_eq, data = Mroz87)\n",
    "print(lmtest::coeftest(heck))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2e2438",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Below is the function for a single bootstrap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d27b19",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "n <- nrow(Mroz87)\n",
    "boot_heck <- function() {\n",
    "  indices <- sample(1:n, n, replace = T) # resample the index set\n",
    "  Mroz87_b <- Mroz87[indices, ] # generate the bootstrap sample\n",
    "  heck_b <- sampleSelection::heckit(selection_eq, outcome_eq, data = Mroz87_b)\n",
    "  return(coef(heck_b))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9708e42b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "* Implementation is just a repeated evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861c4025",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# repeat the bootstrap\n",
    "boot_Rep <- 199\n",
    "Heck_B <- plyr::ldply(.data = 1:boot_Rep, .fun = function(i) boot_heck())\n",
    "\n",
    "# collect the bootstrap outcomes\n",
    "Heck_b_sd <- apply(Heck_B, 2, sd)[1:7]\n",
    "print(Heck_b_sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb69689",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* The standard errors from the analytical expression and those from bootstrap are comparable.\n",
    "* The bootstrap estimates can also be used to directly compute the confidence intervals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79971e6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bootstrap Test\n",
    "\n",
    "* Bootstrap is particularly helpful in inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be32aa0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example\n",
    "\n",
    "* Test a hypothesis about the population mean. \n",
    "\n",
    "* Use $t$-statistic\n",
    "* Distribution of the sample is either\n",
    "  * normal\n",
    "  * zero-centered chi-square \n",
    "\n",
    "* We will show that the bootstrap test size is\n",
    "more precise than that of the asymptotic approximation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1084a642",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# the t-statistic for a null hypothesis mu\n",
    "T_stat <- function(Y, mu) sqrt(n) * (mean(Y) - mu) / sd(Y)\n",
    "\n",
    "# the bootstrap function\n",
    "boot_test <- function(Y, boot_Rep) {\n",
    "  # INPUT; Y: the sample;  boot_Rep: number of bootstrap replications\n",
    "\n",
    "  n <- length(Y)\n",
    "  boot_T <- rep(0, boot_Rep)\n",
    "\n",
    "  for (r in 1:boot_Rep) {   # bootstrap in action\n",
    "    indices <- sample.int(n, n, replace = T) # resampling the index\n",
    "    resampled_Y <- Y[indices] # construct a bootstrap artificial sample\n",
    "    boot_T[r] <- abs(T_stat(resampled_Y, mean(Y)))\n",
    "    # the bootstrapped t-statistic\n",
    "    # mu is replaced by \"mean(Y)\" to mimic the situation under the null\n",
    "  }\n",
    "\n",
    "  boot_critical_value <- quantile(boot_T, 1 - alpha)   # bootstrap critical value\n",
    "  return(boot_critical_value)   # bootstrap test decision\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665a1c18",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bootstrap World\n",
    "\n",
    "* The null hypothesis must be imposed no matter the hypothesized parameter is true value or not.\n",
    "\n",
    "* Bootstrap $t$-statistic is\n",
    "\n",
    "$$\n",
    "T^{*}_{n} = \\frac{\\sqrt{n} (\\bar{X^{*}} - \\bar{X}) } { s^{*}  }.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fec555",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Design the Statistic\n",
    "\n",
    "\n",
    "* In the bootstrap world the **true** distribution is $F_n$\n",
    "* The bootstrap $t$-statistic is centered around $\\bar{X}$, the sample mean of $F_n$\n",
    "* If we wrongly center it around the population mean $\\theta$, then the test will have no power when the null hypothesis is false."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f864ddd4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The following chuck of code report the rejection probability from three decision rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93d6d6c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "compare <- function() {\n",
    "  # this function generates a sample of n observations\n",
    "  # and it returns the testing results from three decision rules\n",
    "\n",
    "  if (distribution == \"normal\") {\n",
    "    X <- rnorm(n)\n",
    "  }\n",
    "  else if (distribution == \"chisq\") {\n",
    "    X <- rchisq(n, df = 3) - 3\n",
    "  }\n",
    "\n",
    "  t_value_X <- T_stat(X, mu) # T-statistic\n",
    "\n",
    "  # compare it to the 97.5% of t-distribution\n",
    "  exact <- abs(t_value_X) > qt(0.975, df = n - 1)\n",
    "  # compare it to the 97.5% of normal distribution\n",
    "  asym <- abs(t_value_X) > 1.96\n",
    "  # decision from bootstrap\n",
    "  boot_rule <- abs(t_value_X) > boot_test(X, boot_Rep)\n",
    "\n",
    "  return(c(exact, asym, boot_rule))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4954b7f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# set the parameters\n",
    "n <- 10\n",
    "distribution <- \"normal\"\n",
    "boot_Rep <- 199\n",
    "MC_rep <- 2000\n",
    "alpha <- 0.05\n",
    "mu <- 0\n",
    "\n",
    "# Monte Carlo simulation and report the rejection probability\n",
    "res <- plyr::ldply(.data = 1:MC_rep, .fun = function(i) compare())\n",
    "colnames(res) <- c(\"exact\", \"asym\", \"bootstrap\")\n",
    "print(colMeans(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405c4d60",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Results\n",
    "\n",
    "* The program reports the empirical size.\n",
    "* Nominal size of the test is 5%. \n",
    "* Bootstrap test is more accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7dd70f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "* When the underlying distribution is a $\\chi^2$, the exact distribution is difficult \n",
    "to derive analytically. \n",
    "* However, we can still compare the asymptotic size with the bootstrap size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf208230",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "distribution <- \"chisq\"\n",
    "\n",
    "res <- plyr::ldply(.data = 1:MC_rep, .fun = function(i) compare())\n",
    "colnames(res) <- c(\"exact?\", \"asym\", \"bootstrap\")\n",
    "print(colMeans(res))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2de5d6e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Here the \"exact test\" is no longer exact. \n",
    "* The asymptotic test works fairly reasonable\n",
    "* Bootstrap is closer to the nominal size 5%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81d285b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reading\n",
    "\n",
    "* [ISLR](https://www.statlearning.com/): Ch 5.2\n",
    "* [CASI](https://hastie.su.domains/CASI/): Ch 10.2-4"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  },
  "rise": {
   "enable_chalkboard": true,
   "scroll": true,
   "theme": "serif"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
